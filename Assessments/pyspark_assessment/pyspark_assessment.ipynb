{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ[\"JAVA_HOME\"] = \"JDK 8\"\n",
    "os.environ[\"PYSPARK_PYTHON\"] = sys.executable\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/02/14 18:27:44 WARN Utils: Your hostname, Mint-T470 resolves to a loopback address: 127.0.1.1; using 192.168.1.249 instead (on interface wlp4s0)\n",
      "25/02/14 18:27:45 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/02/14 18:27:46 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "spark = SparkSession.builder.appName(\"assessment\").getOrCreate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/02/14 18:28:00 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+-----------------+---------+--------------------+----------------+---------+--------------+-------------+--------------+-----------------------+------+----------+--------------+--------+--------------------+---------------+-------------+-------------+-----------+------------------+------+--------+-----------------+-----------------+------------------------+-------------+----------------+-----------------+---------------------+---------------+--------------+------------------+-----------------------+--------------------+\n",
      "|Age|Attrition|   BusinessTravel|DailyRate|          Department|DistanceFromHome|Education|EducationField|EmployeeCount|EmployeeNumber|EnvironmentSatisfaction|Gender|HourlyRate|JobInvolvement|JobLevel|             JobRole|JobSatisfaction|MaritalStatus|MonthlyIncome|MonthlyRate|NumCompaniesWorked|Over18|OverTime|PercentSalaryHike|PerformanceRating|RelationshipSatisfaction|StandardHours|StockOptionLevel|TotalWorkingYears|TrainingTimesLastYear|WorkLifeBalance|YearsAtCompany|YearsInCurrentRole|YearsSinceLastPromotion|YearsWithCurrManager|\n",
      "+---+---------+-----------------+---------+--------------------+----------------+---------+--------------+-------------+--------------+-----------------------+------+----------+--------------+--------+--------------------+---------------+-------------+-------------+-----------+------------------+------+--------+-----------------+-----------------+------------------------+-------------+----------------+-----------------+---------------------+---------------+--------------+------------------+-----------------------+--------------------+\n",
      "| 41|      Yes|    Travel_Rarely|     1102|               Sales|               1|        2| Life Sciences|            1|             1|                      2|Female|        94|             3|       2|     Sales Executive|              4|       Single|         5993|      19479|                 8|     Y|     Yes|               11|                3|                       1|           80|               0|                8|                    0|              1|             6|                 4|                      0|                   5|\n",
      "| 49|       No|Travel_Frequently|      279|Research & Develo...|               8|        1| Life Sciences|            1|             2|                      3|  Male|        61|             2|       2|  Research Scientist|              2|      Married|         5130|      24907|                 1|     Y|      No|               23|                4|                       4|           80|               1|               10|                    3|              3|            10|                 7|                      1|                   7|\n",
      "| 37|      Yes|    Travel_Rarely|     1373|Research & Develo...|               2|        2|         Other|            1|             4|                      4|  Male|        92|             2|       1|Laboratory Techni...|              3|       Single|         2090|       2396|                 6|     Y|     Yes|               15|                3|                       2|           80|               0|                7|                    3|              3|             0|                 0|                      0|                   0|\n",
      "| 33|       No|Travel_Frequently|     1392|Research & Develo...|               3|        4| Life Sciences|            1|             5|                      4|Female|        56|             3|       1|  Research Scientist|              3|      Married|         2909|      23159|                 1|     Y|     Yes|               11|                3|                       3|           80|               0|                8|                    3|              3|             8|                 7|                      3|                   0|\n",
      "| 27|       No|    Travel_Rarely|      591|Research & Develo...|               2|        1|       Medical|            1|             7|                      1|  Male|        40|             3|       1|Laboratory Techni...|              2|      Married|         3468|      16632|                 9|     Y|      No|               12|                3|                       4|           80|               1|                6|                    3|              3|             2|                 2|                      2|                   2|\n",
      "+---+---------+-----------------+---------+--------------------+----------------+---------+--------------+-------------+--------------+-----------------------+------+----------+--------------+--------+--------------------+---------------+-------------+-------------+-----------+------------------+------+--------+-----------------+-----------------+------------------------+-------------+----------------+-----------------+---------------------+---------------+--------------+------------------+-----------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_csv = spark.read.csv(\"HR-Employee-Attrition.csv\", header=True, inferSchema=True)\n",
    "df_csv.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dropped = df_csv.drop(\"EmployeeCount\", \"Over18\", \"StandardHours\")\n",
    "#EmployeeCount has the same value (1) for each entry\n",
    "#All employees are 18+\n",
    "#StandardHours are all the same value (80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age',\n",
       " 'attrition',\n",
       " 'business_travel',\n",
       " 'daily_rate',\n",
       " 'department',\n",
       " 'distance_from_home',\n",
       " 'education',\n",
       " 'education_field',\n",
       " 'employee_number',\n",
       " 'environment_satisfaction',\n",
       " 'gender',\n",
       " 'hourly_rate',\n",
       " 'job_involvement',\n",
       " 'job_level',\n",
       " 'job_role',\n",
       " 'job_satisfaction',\n",
       " 'marital_status',\n",
       " 'monthly_income',\n",
       " 'monthly_rate',\n",
       " 'num_companies_worked',\n",
       " 'over_time',\n",
       " 'percent_salary_hike',\n",
       " 'performance_rating',\n",
       " 'relationship_satisfaction',\n",
       " 'stock_option_level',\n",
       " 'total_working_years',\n",
       " 'training_times_last_year',\n",
       " 'work_life_balance',\n",
       " 'years_at_company',\n",
       " 'years_in_current_role',\n",
       " 'years_since_last_promotion',\n",
       " 'years_with_curr_manager']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# new_columns = {column: re.sub( r\"([a-z])([A-Z])\", r\"\\1_\\2\", column).lower() for column in df_dropped.columns}\n",
    "new_columns = [re.sub(r\"([a-z])([A-Z])\", r\"\\1_\\2\", column).lower() for column in df_dropped.columns]\n",
    "df_snake = df_dropped.toDF(*new_columns)\n",
    "df_snake.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1470"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_snake.dropDuplicates().count()\n",
    "#This data set has no duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+---------------+----------+----------+------------------+---------+---------------+---------------+------------------------+------+-----------+---------------+---------+--------+----------------+--------------+--------------+------------+--------------------+---------+-------------------+------------------+-------------------------+------------------+-------------------+------------------------+-----------------+----------------+---------------------+--------------------------+-----------------------+\n",
      "|age|attrition|business_travel|daily_rate|department|distance_from_home|education|education_field|employee_number|environment_satisfaction|gender|hourly_rate|job_involvement|job_level|job_role|job_satisfaction|marital_status|monthly_income|monthly_rate|num_companies_worked|over_time|percent_salary_hike|performance_rating|relationship_satisfaction|stock_option_level|total_working_years|training_times_last_year|work_life_balance|years_at_company|years_in_current_role|years_since_last_promotion|years_with_curr_manager|\n",
      "+---+---------+---------------+----------+----------+------------------+---------+---------------+---------------+------------------------+------+-----------+---------------+---------+--------+----------------+--------------+--------------+------------+--------------------+---------+-------------------+------------------+-------------------------+------------------+-------------------+------------------------+-----------------+----------------+---------------------+--------------------------+-----------------------+\n",
      "|  0|        0|              0|         0|         0|                 0|        0|              0|              0|                       0|     0|          0|              0|        0|       0|               0|             0|             0|           0|                   0|        0|                  0|                 0|                        0|                 0|                  0|                       0|                0|               0|                    0|                         0|                      0|\n",
      "+---+---------+---------------+----------+----------+------------------+---------+---------------+---------------+------------------------+------+-----------+---------------+---------+--------+----------------+--------------+--------------+------------+--------------------+---------+-------------------+------------------+-------------------------+------------------+-------------------+------------------------+-----------------+----------------+---------------------+--------------------------+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_snake.select([count(when(isnan(i), i)).alias(i) for i in df_snake.columns]).show()\n",
    "#This dataset has no NaN values. I have also confirmed this on data wrangler in VSCode "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "url = \"jdbc:postgresql://localhost:5432/HR\"\n",
    "properties = {\n",
    "    \"user\": \"postgres\",\n",
    "    \"password\": \"Cheesecake\",\n",
    "    \"driver\": \"org.postgresql.Driver\"\n",
    "}\n",
    "\n",
    "df_snake.write.jdbc(url=url, table=\"HR_Employee_Attrition\", properties=properties, mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pandas_df = df_snake.toPandas()\n",
    "\n",
    "pandas_df\n",
    "pandas_df.to_csv(\"updated_HR_employee_attrition.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_snake.createOrReplaceTempView(\"table_view\")\n",
    "# df_queried = spark.sql(\"SELECT * FROM table_view\")\n",
    "# df_queried.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|       average_age|\n",
      "+------------------+\n",
      "|36.923809523809524|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "avg_age_query = \"\"\"\n",
    "    SELECT AVG(age) AS average_age\n",
    "    FROM table_view\n",
    "\"\"\"\n",
    "spark.sql(avg_age_query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|          department|count|\n",
      "+--------------------+-----+\n",
      "|Research & Develo...|  961|\n",
      "+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "most_pop_department = \"\"\"\n",
    "    SELECT department, COUNT(*) as count\n",
    "    FROM table_view\n",
    "    GROUP BY department\n",
    "    ORDER BY count DESC\n",
    "    LIMIT 1;\n",
    "\"\"\"\n",
    "spark.sql(most_pop_department).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------+\n",
      "|median(distance_from_home)|\n",
      "+--------------------------+\n",
      "|                       7.0|\n",
      "+--------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "median_dist_from_home = \"\"\"\n",
    "    SELECT MEDIAN(distance_from_home)\n",
    "    FROM table_view\n",
    "\"\"\"\n",
    "spark.sql(median_dist_from_home).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|education|count|\n",
      "+---------+-----+\n",
      "|        3|  572|\n",
      "+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "most_common_lvl_of_edu = \"\"\"\n",
    "    SELECT education, COUNT(*) as count\n",
    "    FROM table_view\n",
    "    GROUP BY education\n",
    "    ORDER BY COUNT DESC\n",
    "    LIMIT 1;\n",
    "\"\"\"\n",
    "spark.sql(most_common_lvl_of_edu).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
