{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ[\"JAVA_HOME\"] = \"../.JDK 8\" \n",
    "os.environ[\"PYSPARK_PYTHON\"] = sys.executable\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import  *\n",
    "# from pyspark.sql.types import IntegerType\n",
    "\n",
    "# from pyspark.sql.functions import col\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Saving and Project\").getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [(1, \"Moby Dick\", \"Herman Melville\", 1851),\n",
    "        (2, \"Treasure Island\", \"Robert Louis Stevenson\", 1883),\n",
    "        (3, \"Robinson Crusoe\", \"Daniel Defoe\", 1719),\n",
    "        (4, \"The Fellowship of the Ring\", \"J.R.R. Tolkien\", 1954),\n",
    "        (5, \"The Hitchhiker's Guide to the Galaxy\", \"Douglas Adams\", 1979)]\n",
    "\n",
    "columns = [\"ID\", \"book_name\", \"author\", \"publish_date\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+--------------------+------------+\n",
      "| ID|           book_name|              author|publish_date|\n",
      "+---+--------------------+--------------------+------------+\n",
      "|  1|           Moby Dick|     Herman Melville|        1851|\n",
      "|  2|     Treasure Island|Robert Louis Stev...|        1883|\n",
      "|  3|     Robinson Crusoe|        Daniel Defoe|        1719|\n",
      "|  4|The Fellowship of...|      J.R.R. Tolkien|        1954|\n",
      "|  5|The Hitchhiker's ...|       Douglas Adams|        1979|\n",
      "+---+--------------------+--------------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_books = spark.createDataFrame(data, columns)\n",
    "df_books.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have this downloaded, load it into your Python file and into a PySpark DataFrame. Firstly check the file to ensure that the data is of the right type, and there are no null values. Then I want you to tell me which day had the most lightning strikes recorded. Order the dataframe by descending number of strikes, then save it to a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_lightning = spark.read.csv(\"lightening strikes dataset.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- date: date (nullable = true)\n",
      " |-- number_of_strikes: integer (nullable = true)\n",
      " |-- center_point_geom: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_lightning.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------+-----------------+\n",
      "|      date|number_of_strikes|center_point_geom|\n",
      "+----------+-----------------+-----------------+\n",
      "|2018-01-03|              194|    POINT(-75 27)|\n",
      "|2018-01-03|               41|  POINT(-78.4 29)|\n",
      "|2018-01-03|               33|  POINT(-73.9 27)|\n",
      "|2018-01-03|               38|  POINT(-73.8 27)|\n",
      "|2018-01-03|               92|    POINT(-79 28)|\n",
      "+----------+-----------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_lightning.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bydays = df_bydays = df_lightning.groupBy(\"date\").agg(sum(\"number_of_strikes\").alias(\"total_count\")).orderBy(col(\"total_count\").desc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 26:===========================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+\n",
      "|      date|total_count|\n",
      "+----------+-----------+\n",
      "|2018-08-29|    1070457|\n",
      "|2018-08-17|     969774|\n",
      "|2018-08-28|     917199|\n",
      "|2018-08-27|     824589|\n",
      "|2018-08-30|     802170|\n",
      "|2018-08-19|     786225|\n",
      "|2018-08-18|     741180|\n",
      "|2018-08-16|     734475|\n",
      "|2018-08-31|     723624|\n",
      "|2018-08-15|     673455|\n",
      "|2018-08-20|     660501|\n",
      "|2018-08-24|     652101|\n",
      "|2018-08-21|     575985|\n",
      "|2018-08-22|     535986|\n",
      "|2018-08-23|     527955|\n",
      "|2018-08-25|     512100|\n",
      "|2018-08-26|     507894|\n",
      "|2018-06-24|     431587|\n",
      "|2018-07-23|     423031|\n",
      "|2018-06-26|     376955|\n",
      "+----------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_bydays.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_bydays.toPandas().to_csv(\"lightning_count_by_day.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 37:===========================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----------+\n",
      "|center_point_geom|avg_strikes|\n",
      "+-----------------+-----------+\n",
      "|POINT(-95.3 29.4)|      17.52|\n",
      "|POINT(-92.6 24.9)|       6.65|\n",
      "|POINT(-92.2 26.1)|       8.64|\n",
      "|POINT(-91.3 28.1)|      11.44|\n",
      "|POINT(-93.9 28.1)|       12.3|\n",
      "|POINT(-87.4 25.2)|       8.94|\n",
      "|POINT(-86.9 26.4)|      11.91|\n",
      "|POINT(-76.3 26.7)|      14.53|\n",
      "|  POINT(-85.5 26)|      10.03|\n",
      "|POINT(-76.1 25.7)|       11.0|\n",
      "|POINT(-99.9 33.6)|      26.79|\n",
      "|  POINT(-77 26.5)|       9.83|\n",
      "|POINT(-79.6 28.3)|      16.95|\n",
      "|POINT(-78.7 31.9)|      16.14|\n",
      "|POINT(-73.5 29.2)|       5.57|\n",
      "|POINT(-96.5 27.7)|      19.76|\n",
      "|POINT(-95.9 33.7)|      27.16|\n",
      "|POINT(-95.1 34.3)|       34.9|\n",
      "|POINT(-94.7 35.2)|      39.15|\n",
      "|  POINT(-92.8 31)|      25.78|\n",
      "+-----------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_lightning.groupBy(\"center_point_geom\").agg(round(avg(\"number_of_strikes\"), 2).alias(\"avg_strikes\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pandas_df = df_books.toPandas()\n",
    "pandas_df.to_csv(\"book.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
